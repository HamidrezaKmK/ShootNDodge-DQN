{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "930dfb40",
   "metadata": {},
   "source": [
    "# Shoot N Dodge\n",
    "\n",
    "In this assignment, you will be programming an agent to be able to play a new Atari game called *ShootNDodge*.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799fa016",
   "metadata": {},
   "source": [
    "## Game description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8dabb5",
   "metadata": {},
   "source": [
    "\n",
    "## Installing the game\n",
    "\n",
    "The game is provided as a python package and can be run as an **OpenAI-Gym** environment. To do so, you will have to go to the setup folder and install the package on your python virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed3e0bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/hamidreza/Courses/SUT-AI/F2021-P5/DQN/gym-shootndodge\n",
      "Requirement already satisfied: gym in /home/hamidreza/anaconda3/lib/python3.8/site-packages (from gym-shootndodge==0.0.89) (0.21.0)\n",
      "Requirement already satisfied: opencv-python in /home/hamidreza/anaconda3/lib/python3.8/site-packages (from gym-shootndodge==0.0.89) (4.5.5.62)\n",
      "Requirement already satisfied: pillow in /home/hamidreza/anaconda3/lib/python3.8/site-packages (from gym-shootndodge==0.0.89) (8.3.1)\n",
      "Requirement already satisfied: numpy in /home/hamidreza/anaconda3/lib/python3.8/site-packages (from gym-shootndodge==0.0.89) (1.19.5)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/hamidreza/anaconda3/lib/python3.8/site-packages (from gym->gym-shootndodge==0.0.89) (1.6.0)\n",
      "Installing collected packages: gym-shootndodge\n",
      "  Attempting uninstall: gym-shootndodge\n",
      "    Found existing installation: gym-shootndodge 0.0.88\n",
      "    Uninstalling gym-shootndodge-0.0.88:\n",
      "      Successfully uninstalled gym-shootndodge-0.0.88\n",
      "  Running setup.py develop for gym-shootndodge\n",
      "Successfully installed gym-shootndodge\n"
     ]
    }
   ],
   "source": [
    "!pip install -e gym-shootndodge/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e279e101",
   "metadata": {},
   "source": [
    "Now you can easily create the environment similar to any other gym environment using the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5d0e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = 'shootndodge-v0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dae2f8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import gym_shootndodge\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "env = gym.make(ENV_NAME)\n",
    "obs = env.reset()\n",
    "plt.imshow(env.render(mode='rgb_array'), aspect='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d264239",
   "metadata": {},
   "source": [
    "Run the game in frames to see what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66fcfbf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "env = gym.make(ENV_NAME)\n",
    "env.seed(2022)\n",
    "obs = env.reset()\n",
    "a = 2\n",
    "for i in range(5000):\n",
    "    if (i + 1) % 40 == 0:\n",
    "        a = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(a)\n",
    "   \n",
    "    if (i + 1) % 5 == 0:\n",
    "        clear_output(True)\n",
    "        screen = env.render(mode='rgb_array')\n",
    "        plt.imshow(screen, aspect='auto')\n",
    "        plt.show()\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb31477",
   "metadata": {},
   "source": [
    "### Let's play a little\n",
    "\n",
    "Pay attention to zoom and play function. Control: Up arrow, Down arrow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c79dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # does not work in Colab.\n",
    "# # make keyboard interrupt to continue\n",
    "\n",
    "# from gym.utils.play import play\n",
    "\n",
    "# play(env=gym.make(ENV_NAME), zoom=5, fps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ce6b68",
   "metadata": {},
   "source": [
    "### Preprocessing game image\n",
    "\n",
    "The raw Atari image is large, 504x510x3 by default. However, we don't need that level of detail in order to learn them.\n",
    "\n",
    "We can thus save a lot of time by preprocessing game image, including\n",
    "\n",
    "Resizing to a smaller shape, 64 x 64\n",
    "Converting to grayscale\n",
    "Cropping irrelevant image parts (top, bottom and edges)\n",
    "Also please keep one dimension for channel so that final shape would be 1 x 64 x 64.\n",
    "\n",
    "Tip: You can implement your own grayscale converter and assign a huge weight to the red channel. This dirty trick is not necessary but it will speed up learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5683cf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.core import ObservationWrapper\n",
    "from gym.spaces import Box\n",
    "import cv2\n",
    "\n",
    "badblock_colors = [(200, 200, 0), (153, 76, 0), (204, 0, 0)]\n",
    "\n",
    "class PreprocessAtariObs(ObservationWrapper):\n",
    "    def __init__(self, env, gray_scale=False):\n",
    "        \"\"\"A gym wrapper that crops, scales image into the desired shapes and grayscales it.\"\"\"\n",
    "        ObservationWrapper.__init__(self, env)\n",
    "\n",
    "        self.img_size = (64, 64)\n",
    "        self.observation_space = Box(0.0, 1.0, (64, 64, 1 if gray_scale else env.observation_space.shape[2]))\n",
    "\n",
    "        self.gray_scale = gray_scale\n",
    "        \n",
    "    def _to_gray_scale(self, rgb, channel_weights=[0.6, 0.3, 0.1]):\n",
    "        gray_img = np.zeros((rgb.shape[0], rgb.shape[1], 1))\n",
    "        for i in range(rgb.shape[0]):\n",
    "            for j in range(rgb.shape[1]):\n",
    "                gray_img[i, j, 0] = channel_weights[0] * rgb[i,j,0] + channel_weights[1] * rgb[i,j,1] + channel_weights[2] * rgb[i,j,2]\n",
    "        return gray_img\n",
    "\n",
    "\n",
    "    def observation(self, img):\n",
    "        \"\"\"what happens to each observation\"\"\"\n",
    "        # Here's what you need to do:\n",
    "        #  * crop image, remove irrelevant parts\n",
    "        #  * resize image to self.img_size\n",
    "        #     (use imresize from any library you want,\n",
    "        #      e.g. opencv, skimage, PIL, keras)\n",
    "        #  * cast image to grayscale\n",
    "        #  * convert image pixels to (0,1) range, float32 type\n",
    "        #print(\"processing obs\")\n",
    "        img_cropped = img[39:504-39, 39:510-39]\n",
    "        processed_img = cv2.resize(img_cropped.astype(np.float32), self.img_size)\n",
    "        #print(\"HIO\")\n",
    "        if self.gray_scale:\n",
    "            print(\"WHAT!\")\n",
    "            processed_img = self._to_gray_scale(processed_img)\n",
    "        processed_img = (processed_img - processed_img.min()) / processed_img.max()\n",
    "        #print(\"CHIZ\", gray_img.shape)\n",
    "#         pooling_window = 7\n",
    "#         sr, sc = gray_img.shape[0] // pooling_window + 1, gray_img.shape[1] // pooling_window + 1\n",
    "#         resized_img = np.zeros((sr, sc))\n",
    "#         for i in range(sr):\n",
    "#             for j in range(sc):\n",
    "#                 rL = i * pooling_window\n",
    "#                 rR = min(rL + pooling_window, gray_img.shape[0])\n",
    "#                 cL = j * pooling_window\n",
    "#                 cR = min(cL + pooling_window, gray_img.shape[1])\n",
    "#                 block = gray_img[rL:rR,cL:cR]\n",
    "#                 resized_img[i,j] = block.max()\n",
    "        #print(\"processing obs DONE!\")\n",
    "        #print(resized_img.shape, \"SHAPE\")\n",
    "        \n",
    "        #processed_img = (gray_img / gray_img.max()).astype(np.float32)\n",
    "        \n",
    "        #print(resized_img)\n",
    "        #print(resized_img.shape)\n",
    "        return processed_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d4552e",
   "metadata": {},
   "source": [
    "Now we run the code below to check whether the wrapper is ok or not!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23ac7191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3)\n",
      "Formal tests seem fine.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "import gym\n",
    "# spawn game instance for tests\n",
    "env = gym.make(ENV_NAME)  # create raw env\n",
    "env = PreprocessAtariObs(env)\n",
    "observation_shape = env.observation_space.shape\n",
    "n_actions = env.action_space.n\n",
    "env.reset()\n",
    "obs, _, _, _ = env.step(env.action_space.sample())\n",
    "\n",
    "print(obs.shape)\n",
    "# test observation\n",
    "assert obs.ndim == 3, \"observation must be [h, w, c] even in grayscale mode\"\n",
    "# assert obs.shape == observation_shape\n",
    "# assert obs.dtype == 'float32'\n",
    "# assert 0 <= np.min(obs) and np.max(\n",
    "#     obs) <= 1, \"convert image pixels to [0,1] range\"\n",
    "\n",
    "print(\"Formal tests seem fine.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa571140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD7CAYAAABzGc+QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAN40lEQVR4nO3db4hdd53H8fdnE0W3Kk1WEwbT3SqEVpFtKrFbqSxarWRdsX3SpQVhWApBcJcKgqS7sKXPfCT6YFGC/wK6dUvVTegDNYzK7gOpSbRd2yZtXLe2oTGjuKLrA9nqdx/MCTs7vencmbn3znzj+wXDOec3587v+yXJJye/e05uqgpJUj9/sNkFSJLWxwCXpKYMcElqygCXpKYMcElqygCXpKY2FOBJDiR5MskPkxyaVFGSpNVlvfeBJ9kGPAXcApwDTgB3VtUTkytPknQp2zfw2huAH1bVjwCSfAm4FbhkgCfxqSFJWrufVdVrVg5uZAnltcCzy47PDWOSpMn68ajBjVyBZ8TYC66wkxwEDm5gHknSCBsJ8HPAVcuO9wDPrTypqg4Dh8ElFEmapI0soZwA9iZ5XZKXAncAxyZTliRpNeu+Aq+q55P8DfB1YBvw2ap6fGKVSZJe1LpvI1zXZC6hSNJ6nKqq/SsHfRJTkpoywCWpKQNckpoywCWpKQNckpoywCWpKQNckpoywCWpKQNckpoywCWpKQNckpoywCWpKQNckpoywCWpKQNckpoywCWpKQNckpoywCWpKQNckpoywCWpKQNckpoywCWpKQNckpoywCWpKQNckppaNcCTfDbJYpLHlo3tTHI8ydlhu2O6ZUqSVhrnCvzzwIEVY4eAharaCywMx5KkGVo1wKvqX4Gfrxi+FTgy7B8BbptsWZKk1ax3DXx3VZ0HGLa7JleSJGkc26c9QZKDwMFpzyNJv2/WG+AXksxV1fkkc8DipU6sqsPAYYAktc75JE3Atdde+4KxM2fOzGTuEydOjBx/y1veMpP5x3Xvvfdu6vz33Xff2OeudwnlGDA/7M8DR9f5cyRJ6zTObYT3A98BrklyLsldwEeBW5KcBW4ZjiVJM7TqEkpV3XmJb71zwrVIktZg6m9iSto6ZrXePcpWW+sG2Lt376bO/9RTT23o9T5KL0lNGeCS1FSqZndnn7cRStK6nKqq/SsHvQKXpKYMcElqygCXpKYMcElqygCXpKYMcElqygCXpKYMcElqygCXpKYMcElqygCXpKYMcElqygCXpKYMcElqygCXpKYMcElqygCXpKYMcElqygCXpKYMcElqygCXpKZWDfAkVyX5VpLTSR5PcvcwvjPJ8SRnh+2O6ZcrSbponCvw54EPV9UbgBuBDyZ5I3AIWKiqvcDCcCxJmpFVA7yqzlfV94b9XwGngdcCtwJHhtOOALdNqUZJ0ghrWgNPcjVwPfAwsLuqzsNSyAO7Jl6dJOmSto97YpJXAF8GPlRVv0wy7usOAgfXV54k6VLGugJP8hKWwvuLVfWVYfhCkrnh+3PA4qjXVtXhqtpfVfsnUbAkack4d6EE+Axwuqo+tuxbx4D5YX8eODr58iRJl5KqevETkrcB/wb8APjdMPx3LK2DPwD8MfAMcHtV/XyVn/Xik0mSRjk1ahVj1QCfJANcktZlZID7JKYkNWWAS1JTBrgkNWWAS1JTBrgkNWWAS1JTBrgkNWWAS1JTBrgkNWWAS1JTBrgkNWWAS1JTBrgkNWWAS1JTBrgkNWWAS1JTBrgkNWWAS1JTBrgkNWWAS1JTBrgkNWWAS1JTBrgkNWWAS1JTBrgkNbVqgCd5WZLvJnk0yeNJ7hvGdyY5nuTssN0x/XIlSReNcwX+G+DmqroO2AccSHIjcAhYqKq9wMJwLEmakVUDvJb893D4kuGrgFuBI8P4EeC2aRQoSRptrDXwJNuSPAIsAser6mFgd1WdBxi2u6ZWpSTpBcYK8Kr6bVXtA/YANyR507gTJDmY5GSSk+usUZI0wpruQqmqXwDfBg4AF5LMAQzbxUu85nBV7a+q/RsrVZK03Dh3obwmyZXD/suBdwFngGPA/HDaPHB0SjVKkkbYPsY5c8CRJNtYCvwHquqhJN8BHkhyF/AMcPsU65QkrZCqmt1kyewmk6TLx6lRy9A+iSlJTRngktSUAS5JTY3zJubvnfvvv/8FY3feeedM5v7ABz4wcvxTn/rUTOaX1IdX4JLUlAEuSU0Z4JLUlPeBS9LW533gknQ5McAlqSkDXJKaMsAlqSkDXJKaMsAlqSkDXJKaMsAlqSkDXJKaMsAlqSkDXJKaMsAlqSkDXJKaMsAlqSkDXJKaMsAlqSkDXJKaGjvAk2xL8v0kDw3HO5McT3J22O6YXpmSpJXWcgV+N3B62fEhYKGq9gILw7EkaUbGCvAke4C/BD69bPhW4MiwfwS4baKVSZJe1LhX4B8HPgL8btnY7qo6DzBsd022NEnSi1k1wJO8F1isqlPrmSDJwSQnk5xcz+slSaNtH+Ocm4D3JXkP8DLgVUm+AFxIMldV55PMAYujXlxVh4HDAElqQnVL0u+9Va/Aq+qeqtpTVVcDdwDfrKr3A8eA+eG0eeDo1KqUJL3ARu4D/yhwS5KzwC3DsSRpRlI1u1UNl1AkaV1OVdX+lYM+iSlJTRngktSUAS5JTRngktSUAS5JTRngktSUAS5JTRngktSUAS5JTRngktSUAS5JTRngktSUAS5JTRngktSUAS5JTRngktSUAS5JTRngktSUAS5JTRngktSUAS5JTRngktSUAS5JTRngktSUAS5JTW0f56QkTwO/An4LPF9V+5PsBP4ZuBp4Gvirqvqv6ZQpSVppLVfg76iqfVW1fzg+BCxU1V5gYTiWJM3IRpZQbgWODPtHgNs2XI0kaWzjBngB30hyKsnBYWx3VZ0HGLa7plGgJGm0sdbAgZuq6rkku4DjSc6MO8EQ+AdXPVGStCZjXYFX1XPDdhH4KnADcCHJHMCwXbzEaw9X1f5la+eSpAlYNcCTXJHklRf3gXcDjwHHgPnhtHng6LSKlCS90DhLKLuBrya5eP4/VdXXkpwAHkhyF/AMcPv0ypQkrZSqmt1kyewmk6TLx6lRy9A+iSlJTRngktSUAS5JTRngktSUAS5JTRngktSUAS5JTRngktSUAS5JTRngktSUAS5JTRngktSUAS5JTRngktTUuB+pJm2Kundjr899k6lD2oq8ApekpgxwSWrKJRRJmqCNfsjZ0qdXjscrcElqygCXpKYMcElqygCXpKYMcElqygCXpKZSG73nZS2TJbObTJI2wZRuIzxVVftXDo51BZ7kyiQPJjmT5HSStybZmeR4krPDdsfGypYkrcW4SyifAL5WVdcC1wGngUPAQlXtBRaGY0nSjKy6hJLkVcCjwOtr2clJngTeXlXnk8wB366qa1b5WS6hSNLarXsJ5fXAT4HPJfl+kk8nuQLYXVXnAYbtromWK0l6UeME+HbgzcAnq+p64NesYbkkycEkJ5OcXGeNkqQRxgnwc8C5qnp4OH6QpUC/MCydMGwXR724qg5X1f5Rl/+SpPVbNcCr6ifAs0kurm+/E3gCOAbMD2PzwNGpVChJGmnc/072b4EvJnkp8CPgr1kK/weS3AU8A9w+nRIlSaP4II8kbX3rf5BHkrT1GOCS1JQBLklNGeCS1JQBLklNGeCS1JQBLklNjfsgz6T8DPjxsP/q4fhyYT9b3+XWk/1sbZPs509GDc70QZ7/N3Fy8nL6/1HsZ+u73Hqyn61tFv24hCJJTRngktTUZgb44U2cexrsZ+u73Hqyn61t6v1s2hq4JGljXEKRpKZmHuBJDiR5MskPk7T8JPskn02ymOSxZWM7kxxPcnbY7tjMGtciyVVJvpXkdJLHk9w9jLfsKcnLknw3yaNDP/cN4y37uSjJtuFzaR8ajrv383SSHyR55OJHLnbuKcmVSR5Mcmb4s/TWafcz0wBPsg34R+AvgDcCdyZ54yxrmJDPAwdWjB0CFqpqL7DAGj43dAt4HvhwVb0BuBH44PDr0rWn3wA3V9V1wD7gQJIb6dvPRXcDp5cdd+8H4B1VtW/Z7Xade/oE8LWquha4jqVfq+n2U1Uz+wLeCnx92fE9wD2zrGGCvVwNPLbs+ElgbtifA57c7Bo30NtR4JbLoSfgD4HvAX/WuR9gzxAANwMPDWNt+xlqfhp49Yqxlj0BrwL+k+F9xVn1M+sllNcCzy47PjeMXQ52V9V5gGG7a5PrWZckVwPXAw/TuKdhueERlj5s+3gtfSh3236AjwMfAX63bKxzPwAFfCPJqSQHh7GuPb0e+CnwuWGZ69NJrmDK/cw6wDNizNtgtogkrwC+DHyoqn652fVsRFX9tqr2sXTlekOSN21ySeuW5L3AYlWd2uxaJuymqnozS0uqH0zy55td0AZsB94MfLKqrgd+zQyWf2Yd4OeAq5Yd7wGem3EN03IhyRzAsF3c5HrWJMlLWArvL1bVV4bh1j0BVNUvgG+z9J5F135uAt6X5GngS8DNSb5A334AqKrnhu0i8FXgBvr2dA44N/xLD+BBlgJ9qv3MOsBPAHuTvG74hPs7gGMzrmFajgHzw/48S+vILSQJ8BngdFV9bNm3WvaU5DVJrhz2Xw68CzhD036q6p6q2lNVV7P0Z+abVfV+mvYDkOSKJK+8uA+8G3iMpj1V1U+AZ5NcMwy9E3iCafezCYv97wGeAv4D+PvNfvNhnT3cD5wH/oelv3nvAv6IpTeZzg7bnZtd5xr6eRtLS1n/DjwyfL2na0/AnwLfH/p5DPiHYbxlPyt6ezv/9yZm235YWjN+dPh6/GIWNO9pH3By+H33L8COaffjk5iS1JRPYkpSUwa4JDVlgEtSUwa4JDVlgEtSUwa4JDVlgEtSUwa4JDX1v3hFJ7UrT4x9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "obs = env.reset()\n",
    "a = 0\n",
    "for i in range(1000):\n",
    "    if (i + 1) % 40 == 0:\n",
    "        a = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(a)\n",
    "    #print(observation.shape)\n",
    "    #print(observation)\n",
    "    if (i + 1) % 5 == 0:\n",
    "        clear_output(True)\n",
    "        #print(observation.shape)\n",
    "        #plt.imshow(observation.astype(np.int32))\n",
    "        plt.imshow(observation, interpolation='none', aspect='auto')\n",
    "        plt.show()\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d256a3",
   "metadata": {},
   "source": [
    "Store frames in frame buffer:\n",
    "\n",
    "-- PROBLEM: the image seems flashy!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22288d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gym.spaces.box import Box\n",
    "from gym.core import Wrapper\n",
    "\n",
    "# TODO: Maybe consequtive frames are not the best because they don't capture movement as much\n",
    "\n",
    "class FrameBuffer(Wrapper):\n",
    "    def __init__(self, env, n_frames=16, frame_batch_size=4):\n",
    "        \"\"\"A gym wrapper that reshapes, crops and scales image into the desired shapes\"\"\"\n",
    "        \n",
    "        assert n_frames % frame_batch_size == 0, \"number of frames shoud be dividable by frame_batch_size\"\n",
    "        \n",
    "        super(FrameBuffer, self).__init__(env)\n",
    "        height, width, n_channels= env.observation_space.shape\n",
    "        obs_shape = (height, width, n_channels * n_frames // frame_batch_size)\n",
    "        frame_buffer_shape = (height, width, n_channels * n_frames)\n",
    "        self.observation_space = Box(0.0, 1.0, obs_shape)\n",
    "        self.framebuffer = np.zeros(frame_buffer_shape, 'float32')\n",
    "        self.compressed_buffer = np.zeros(obs_shape, 'float32')\n",
    "        self.frame_batch_size = frame_batch_size\n",
    "        self.cyclic = frame_batch_size\n",
    "        \n",
    "    def reset(self):\n",
    "        \"\"\"resets breakout, returns initial frames\"\"\"\n",
    "        self.framebuffer = np.zeros_like(self.framebuffer)\n",
    "        self.update_buffer(self.env.reset())\n",
    "        return self.compressed_buffer\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"plays breakout for 1 step, returns frame buffer\"\"\"\n",
    "        new_img, reward, done, info = self.env.step(action)\n",
    "        self.update_buffer(new_img)\n",
    "        return self.compressed_buffer, reward, done, info\n",
    "\n",
    "    def update_buffer(self, img):\n",
    "        offset = self.env.observation_space.shape[2]\n",
    "        axis = 2\n",
    "        cropped_framebuffer = self.framebuffer[:,:,:-offset]\n",
    "        self.framebuffer = np.concatenate(\n",
    "            [img, cropped_framebuffer], axis=axis)\n",
    "        \n",
    "        self.cyclic -= 1\n",
    "        if self.cyclic == 0:\n",
    "            self.cyclic = self.frame_batch_size\n",
    "            self.compressed_buffer = self.compressed_buffer[:,:,:-offset]\n",
    "            batch_section = self.framebuffer[:,:,:offset*self.cyclic]\n",
    "            picker = offset * np.arange(self.cyclic)\n",
    "            for i in range(offset):\n",
    "                #print((offset - i - 1) + picker)\n",
    "                avg = np.expand_dims(np.mean(batch_section[:,:,(offset - i - 1) + picker], axis=2), 2)\n",
    "            \n",
    "                self.compressed_buffer = np.concatenate(\n",
    "                    [avg, self.compressed_buffer], axis=axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "592a7a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(64, 64, 12)\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "env = gym.make(ENV_NAME)\n",
    "env = PreprocessAtariObs(env)\n",
    "env = FrameBuffer(env)\n",
    "n_actions = env.action_space.n\n",
    "state_shape = env.observation_space.shape\n",
    "print(state_shape)\n",
    "s = env.reset()\n",
    "# s, _, _, _ = env.step(env.action_space.sample())\n",
    "# s, _, _, _ = env.step(env.action_space.sample())\n",
    "# print(\"HO1\")\n",
    "# s, _, _, _ = env.step(env.action_space.sample())\n",
    "# print(\"HO2\")\n",
    "# s, _, _, _ = env.step(env.action_space.sample())\n",
    "a = 0\n",
    "for i in range(1000):\n",
    "    if (i + 1) % 5 == 0:\n",
    "        a = env.action_space.sample()\n",
    "    s, _, done, _ = env.step(a)\n",
    "    if done:\n",
    "        break\n",
    "    if (i + 1) % 20 == 0:\n",
    "        clear_output(True)\n",
    "        for f in range(4):\n",
    "            plt.imshow(s[:,:,f * 3:f * 3 + 3], interpolation='none', aspect='auto')\n",
    "            plt.show()\n",
    "print(n_actions)\n",
    "print(state_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc491dc",
   "metadata": {},
   "source": [
    "### The DQN architecture\n",
    "\n",
    "We now need to build a neural network that can map images to state q-values. This network will be called on every agent's step so it better not be resnet-152 unless you have an array of GPUs. Instead, you can use strided convolutions with a small number of features to save time and memory.\n",
    "\n",
    "You can build any architecture you want, but for reference, here's something that will more or less work:\n",
    "\n",
    "(HERE SHOULD BE A PHOTO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14091188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# those who have a GPU but feel unfair to use it can uncomment:\n",
    "# device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4013915",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent(nn.Module):\n",
    "    def __init__(self, env, epsilon=0):\n",
    "\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.state_shape = (env.observation_space.shape[2],\n",
    "                            env.observation_space.shape[0],\n",
    "                            env.observation_space.shape[1])\n",
    "        self.n_actions = env.action_space.n\n",
    "        self.conv1 = nn.Conv2d(self.state_shape[0], 16, (3, 3), 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, (3, 3), 2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, (3, 3), 2)\n",
    "        self.linear = self.linear1 = nn.Linear(3136, self.n_actions)\n",
    "        \n",
    "        # TODO: one RELU for all?!\n",
    "        self.ReLU = nn.ReLU()\n",
    "        self.Flatten = nn.Flatten()\n",
    "        \n",
    "        # Define your network body here. Please make sure agent is fully contained here\n",
    "        # nn.Flatten() can be useful\n",
    "        #<YOUR CODE>\n",
    "        #self.layers = nn.Sequential(\n",
    "            \n",
    "        #)\n",
    "\n",
    "    def forward(self, state_t):\n",
    "        \"\"\"\n",
    "        takes agent's observation (tensor), returns qvalues (tensor)\n",
    "        :param state_t: a batch of 4-frame buffers, shape = [batch_size, h, w, 4 * c]\n",
    "        \"\"\"\n",
    "        # Use your network to compute qvalues for given state\n",
    "        state_t = state_t.transpose(3, 2)\n",
    "        state_t = state_t.transpose(2, 1)\n",
    "        state_t = self.ReLU(self.conv1(state_t))\n",
    "        state_t = self.ReLU(self.conv2(state_t))\n",
    "        state_t = self.ReLU(self.conv3(state_t))\n",
    "        qvalues = self.ReLU(self.linear(self.Flatten(state_t)))\n",
    "        \n",
    "\n",
    "        assert qvalues.requires_grad, \"qvalues must be a torch tensor with grad\"\n",
    "        assert len(\n",
    "            qvalues.shape) == 2 and qvalues.shape[0] == state_t.shape[0] and qvalues.shape[1] == self.n_actions\n",
    "\n",
    "        return qvalues\n",
    "\n",
    "    def get_qvalues(self, states):\n",
    "        \"\"\"\n",
    "        like forward, but works on numpy arrays, not tensors\n",
    "        \"\"\"\n",
    "        model_device = next(self.parameters()).device\n",
    "        states = torch.tensor(states, device=model_device, dtype=torch.float)\n",
    "        qvalues = self.forward(states)\n",
    "        return qvalues.data.cpu().numpy()\n",
    "\n",
    "    def sample_actions(self, qvalues):\n",
    "        \"\"\"pick actions given qvalues. Uses epsilon-greedy exploration strategy. \"\"\"\n",
    "        epsilon = self.epsilon\n",
    "        batch_size, n_actions = qvalues.shape\n",
    "\n",
    "        random_actions = np.random.choice(n_actions, size=batch_size)\n",
    "        best_actions = qvalues.argmax(axis=-1)\n",
    "\n",
    "        should_explore = np.random.choice(\n",
    "            [0, 1], batch_size, p=[1-epsilon, epsilon])\n",
    "        return np.where(should_explore, random_actions, best_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee68ea6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space shape: (64, 64, 12)\n",
      "Action space count: 3\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(ENV_NAME)\n",
    "env = PreprocessAtariObs(env)\n",
    "env = FrameBuffer(env)\n",
    "print('Observation space shape: {}\\nAction space count: {}'.format(env.observation_space.shape, env.action_space.n))\n",
    "agent = DQNAgent(env, epsilon=0.5).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d621b4",
   "metadata": {},
   "source": [
    "Run the agent to see if it encounters any errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cf379ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(env, agent, n_games=1, greedy=False, t_max=10000, visualize=False):\n",
    "    \"\"\" Plays n_games full games. If greedy, picks actions as argmax(qvalues). Returns mean reward. \"\"\"\n",
    "    rewards = []\n",
    "    for _ in trange(n_games):\n",
    "        s = env.reset()\n",
    "        reward = 0\n",
    "        for t in range(t_max):\n",
    "            qvalues = agent.get_qvalues([s])\n",
    "            action = qvalues.argmax(axis=-1)[0] if greedy else agent.sample_actions(qvalues)[0]\n",
    "            s, r, done, _ = env.step(action)\n",
    "            if visualize and (t + 1) % 20 == 0:\n",
    "                clear_output(True)\n",
    "                plt.imshow(s[:,:,0:3], interpolation='none', aspect='auto')\n",
    "                plt.show()   \n",
    "                #print(reward)\n",
    "            reward += r\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        rewards.append(reward)\n",
    "    return np.mean(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56bcddb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-771.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(env, agent, n_games=15, visualize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b83e96",
   "metadata": {},
   "source": [
    "### Experience Replay\n",
    "\n",
    "The interface is fairly simple:\n",
    "* `exp_replay.add(obs, act, rw, next_obs, done)` - saves (s,a,r,s',done) tuple into the buffer\n",
    "* `exp_replay.sample(batch_size)` - returns observations, actions, rewards, next_observations and is_done for batch_size random samples.\n",
    "* `len(exp_replay)` - returns number of elements stored in replay buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02d5a91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is shamelessly stolen from\n",
    "# https://github.com/openai/baselines/blob/master/baselines/deepq/replay_buffer.py\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, size):\n",
    "        \"\"\"Create Replay buffer.\n",
    "        Parameters\n",
    "        ----------\n",
    "        size: int\n",
    "            Max number of transitions to store in the buffer. When the buffer\n",
    "            overflows the old memories are dropped.\n",
    "        \"\"\"\n",
    "        self._storage = []\n",
    "        self._maxsize = size\n",
    "        self._next_idx = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._storage)\n",
    "\n",
    "    def add(self, obs_t, action, reward, obs_tp1, done):\n",
    "        # fill the data cyclically, if the list is not yet complete append it\n",
    "        data = (obs_t, action, reward, obs_tp1, done)\n",
    "\n",
    "        if self._next_idx >= len(self._storage):\n",
    "            self._storage.append(data)\n",
    "        else:\n",
    "            self._storage[self._next_idx] = data\n",
    "        self._next_idx = (self._next_idx + 1) % self._maxsize\n",
    "\n",
    "    def _encode_sample(self, idxes):\n",
    "        obses_t, actions, rewards, obses_tp1, dones = [], [], [], [], []\n",
    "        for i in idxes:\n",
    "            data = self._storage[i]\n",
    "            obs_t, action, reward, obs_tp1, done = data\n",
    "            obses_t.append(np.array(obs_t, copy=False))\n",
    "            actions.append(np.array(action, copy=False))\n",
    "            rewards.append(reward)\n",
    "            obses_tp1.append(np.array(obs_tp1, copy=False))\n",
    "            dones.append(done)\n",
    "        return (\n",
    "            np.array(obses_t),\n",
    "            np.array(actions),\n",
    "            np.array(rewards),\n",
    "            np.array(obses_tp1),\n",
    "            np.array(dones)\n",
    "        )\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"Sample a batch of experiences.\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size: int\n",
    "            How many transitions to sample.\n",
    "        Returns\n",
    "        -------\n",
    "        obs_batch: np.array\n",
    "            batch of observations\n",
    "        act_batch: np.array\n",
    "            batch of actions executed given obs_batch\n",
    "        rew_batch: np.array\n",
    "            rewards received as results of executing act_batch\n",
    "        next_obs_batch: np.array\n",
    "            next set of observations seen after executing act_batch\n",
    "        done_mask: np.array\n",
    "            done_mask[i] = 1 if executing act_batch[i] resulted in\n",
    "            the end of an episode and 0 otherwise.\n",
    "        \"\"\"\n",
    "        idxes = [\n",
    "            random.randint(0, len(self._storage) - 1)\n",
    "            for _ in range(batch_size)\n",
    "        ]\n",
    "        return self._encode_sample(idxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26163fd0",
   "metadata": {},
   "source": [
    "Check whether the Replay Buffer works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a65ed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exp_replay = ReplayBuffer(10)\n",
    "\n",
    "for _ in range(30):\n",
    "    exp_replay.add(env.reset(), env.action_space.sample(),\n",
    "                   1.0, env.reset(), done=False)\n",
    "\n",
    "obs_batch, act_batch, reward_batch, next_obs_batch, is_done_batch = exp_replay.sample(\n",
    "    5)\n",
    "\n",
    "assert len(exp_replay) == 10, \"experience replay size should be 10 because that's what maximum capacity is\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f63f46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6819676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_and_record(initial_state, agent, env, exp_replay, n_steps=1):\n",
    "    \"\"\"\n",
    "    Play the game for exactly n steps, record every (s,a,r,s', done) to replay buffer. \n",
    "    Whenever game ends, add record with done=True and reset the game.\n",
    "    It is guaranteed that env has done=False when passed to this function.\n",
    "\n",
    "    PLEASE DO NOT RESET ENV UNLESS IT IS \"DONE\"\n",
    "\n",
    "    :returns: return sum of rewards over time and the state in which the env stays\n",
    "    \"\"\"\n",
    "    s = initial_state\n",
    "    sum_rewards = 0\n",
    "\n",
    "    # Play the game for n_steps as per instructions above\n",
    "    for i in range(n_steps):\n",
    "        q_values = agent.get_qvalues([s])\n",
    "        a = agent.sample_actions(q_values)[0]\n",
    "        s_, rwd, done, info = env.step(a)\n",
    "        sum_rewards += rwd\n",
    "        exp_replay.add(s, a, rwd, s_, done)\n",
    "        if done:\n",
    "            s = env.reset()\n",
    "        else:\n",
    "            s = s_\n",
    "            \n",
    "    return sum_rewards, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ddb006c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "exp_replay = ReplayBuffer(2000)\n",
    "\n",
    "state = env.reset()\n",
    "play_and_record(state, agent, env, exp_replay, n_steps=1000)\n",
    "\n",
    "# if you're using your own experience replay buffer, some of those tests may need correction.\n",
    "# just make sure you know what your code does\n",
    "assert len(exp_replay) == 1000, \"play_and_record should have added exactly 1000 steps, \"\\\n",
    "                                 \"but instead added %i\" % len(exp_replay)\n",
    "is_dones = list(zip(*exp_replay._storage))[-1]\n",
    "\n",
    "for _ in range(100):\n",
    "    obs_batch, act_batch, reward_batch, next_obs_batch, is_done_batch = exp_replay.sample(\n",
    "        10)\n",
    "    assert obs_batch.shape == next_obs_batch.shape == (10,) + state_shape\n",
    "    assert act_batch.shape == (\n",
    "        10,), \"actions batch should have shape (10,) but is instead %s\" % str(act_batch.shape)\n",
    "    assert reward_batch.shape == (\n",
    "        10,), \"rewards batch should have shape (10,) but is instead %s\" % str(reward_batch.shape)\n",
    "    assert is_done_batch.shape == (\n",
    "        10,), \"is_done batch should have shape (10,) but is instead %s\" % str(is_done_batch.shape)\n",
    "    assert [int(i) in (0, 1)\n",
    "            for i in is_dones], \"is_done should be strictly True or False\"\n",
    "    assert [\n",
    "        0 <= a < n_actions for a in act_batch], \"actions should be within [0, n_actions)\"\n",
    "\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9131c23",
   "metadata": {},
   "source": [
    "How to use target networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9dd6b4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_network = DQNAgent(env, epsilon=0.5).to(device)\n",
    "# This is how you can load weights from agent into target network\n",
    "target_network.load_state_dict(agent.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8500c3ab",
   "metadata": {},
   "source": [
    "### Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef092912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_td_loss(states, actions, rewards, next_states, is_done,\n",
    "                    agent, target_network,\n",
    "                    gamma=0.99,\n",
    "                    check_shapes=False,\n",
    "                    device=device):\n",
    "    \"\"\" Compute td loss using torch operations only. Use the formulae above. \"\"\"\n",
    "    states = torch.tensor(states, device=device, dtype=torch.float)    # shape: [batch_size, *state_shape]\n",
    "\n",
    "    # for some torch reason should not make actions a tensor\n",
    "    actions = torch.tensor(actions, device=device, dtype=torch.long)    # shape: [batch_size]\n",
    "    rewards = torch.tensor(rewards, device=device, dtype=torch.float)  # shape: [batch_size]\n",
    "    # shape: [batch_size, *state_shape]\n",
    "    next_states = torch.tensor(next_states, device=device, dtype=torch.float)\n",
    "    is_done = torch.tensor(\n",
    "        is_done.astype('float32'),\n",
    "        device=device,\n",
    "        dtype=torch.float\n",
    "    )  # shape: [batch_size]\n",
    "    is_not_done = 1 - is_done\n",
    "\n",
    "    # get q-values for all actions in current states\n",
    "    predicted_qvalues = agent(states)\n",
    "\n",
    "    # compute q-values for all actions in next states\n",
    "    predicted_next_qvalues = target_network(next_states)\n",
    "    \n",
    "    # select q-values for chosen actions\n",
    "    predicted_qvalues_for_actions = predicted_qvalues[range(\n",
    "        len(actions)), actions]\n",
    "\n",
    "    # compute V*(next_states) using predicted next q-values\n",
    "    next_state_values = predicted_next_qvalues.max(-1)[0]\n",
    "\n",
    "    assert next_state_values.dim(\n",
    "    ) == 1 and next_state_values.shape[0] == states.shape[0], \"must predict one value per state\"\n",
    "\n",
    "    # compute \"target q-values\" for loss - it's what's inside square parentheses in the above formula.\n",
    "    # at the last state use the simplified formula: Q(s,a) = r(s,a) since s' doesn't exist\n",
    "    # you can multiply next state values by is_not_done to achieve this.\n",
    "    target_qvalues_for_actions = rewards + is_not_done * gamma * next_state_values\n",
    "\n",
    "    # mean squared error loss to minimize\n",
    "    loss = torch.mean((predicted_qvalues_for_actions -\n",
    "                       target_qvalues_for_actions.detach()) ** 2)\n",
    "\n",
    "    if check_shapes:\n",
    "        assert predicted_next_qvalues.data.dim(\n",
    "        ) == 2, \"make sure you predicted q-values for all actions in next state\"\n",
    "        assert next_state_values.data.dim(\n",
    "        ) == 1, \"make sure you computed V(s') as maximum over just the actions axis and not all axes\"\n",
    "        assert target_qvalues_for_actions.data.dim(\n",
    "        ) == 1, \"there's something wrong with target q-values, they must be a vector\"\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10559dba",
   "metadata": {},
   "source": [
    "Sanity checks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "964f083b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "loss must be differentiable w.r.t. network weights",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_35740/1446038081.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m assert loss.requires_grad and tuple(loss.data.size()) == (\n\u001B[1;32m     10\u001B[0m     ), \"you must return scalar loss - mean over batch\"\n\u001B[0;32m---> 11\u001B[0;31m assert np.any(next(agent.parameters()).grad.data.cpu().numpy() !=\n\u001B[0m\u001B[1;32m     12\u001B[0m               0), \"loss must be differentiable w.r.t. network weights\"\n\u001B[1;32m     13\u001B[0m \u001B[0;32massert\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mall\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtarget_network\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgrad\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"target network should not have grads\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAssertionError\u001B[0m: loss must be differentiable w.r.t. network weights"
     ]
    }
   ],
   "source": [
    "obs_batch, act_batch, reward_batch, next_obs_batch, is_done_batch = exp_replay.sample(\n",
    "    10)\n",
    "\n",
    "loss = compute_td_loss(obs_batch, act_batch, reward_batch, next_obs_batch, is_done_batch,\n",
    "                       agent, target_network,\n",
    "                       gamma=0.99, check_shapes=True)\n",
    "loss.backward()\n",
    "\n",
    "assert loss.requires_grad and tuple(loss.data.size()) == (\n",
    "    ), \"you must return scalar loss - mean over batch\"\n",
    "assert np.any(next(agent.parameters()).grad.data.cpu().numpy() !=\n",
    "              0), \"loss must be differentiable w.r.t. network weights\"\n",
    "assert np.all(next(target_network.parameters()).grad is None), \"target network should not have grads\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7946cf59",
   "metadata": {},
   "source": [
    "## Main Learning Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bf843130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange, tqdm\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b1aea40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fcdfdd80970>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 2022#<YOUR CODE: your favourite random seed>\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d72d0384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 12)\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(ENV_NAME)\n",
    "env.seed(seed)\n",
    "env = PreprocessAtariObs(env)\n",
    "env = FrameBuffer(env)\n",
    "state_shape = env.observation_space.shape\n",
    "n_actions = env.action_space.n\n",
    "print(state_shape)\n",
    "print(n_actions)\n",
    "state = env.reset()\n",
    "agent = DQNAgent(env, epsilon=1).to(device)\n",
    "target_network = DQNAgent(env).to(device)\n",
    "target_network.load_state_dict(agent.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e36f656",
   "metadata": {},
   "source": [
    "Buffer of size  104  fits into 5 Gb RAM.\n",
    "\n",
    "Larger sizes ( 105  and  106  are common) can be used. It can improve the learning, but  104  is quiet enough.  102  will probably fail learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff321a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "def is_enough_ram(min_available_gb=0.1):\n",
    "    mem = psutil.virtual_memory()\n",
    "    return mem.available >= min_available_gb * (1024 ** 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d07e8a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 99/100 [02:49<00:01,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exp_replay = ReplayBuffer(10**4)\n",
    "for i in tqdm(range(100)):\n",
    "    if not is_enough_ram(min_available_gb=0.1):\n",
    "        print(\"\"\"\n",
    "            Less than 100 Mb RAM available. \n",
    "            Make sure the buffer size in not too huge.\n",
    "            Also check, maybe other processes consume RAM heavily.\n",
    "            \"\"\"\n",
    "             )\n",
    "        break\n",
    "    play_and_record(state, agent, env, exp_replay, n_steps=10**2)\n",
    "    if len(exp_replay) == 10**4:\n",
    "        break\n",
    "print(len(exp_replay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "78174d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps_per_epoch = 1\n",
    "batch_size = 16\n",
    "total_steps = 3 * 10**6\n",
    "decay_steps = 10**6\n",
    "\n",
    "opt = torch.optim.Adam(agent.parameters(), lr=1e-4)\n",
    "\n",
    "init_epsilon = 1\n",
    "final_epsilon = 0.1\n",
    "\n",
    "loss_freq = 50\n",
    "refresh_target_network_freq = 5000\n",
    "eval_freq = 5000\n",
    "\n",
    "max_grad_norm = 50\n",
    "\n",
    "n_lives = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7d080ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rw_history = []\n",
    "td_loss_history = []\n",
    "grad_norm_history = []\n",
    "initial_state_v_history = []\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fd010c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import convolve, gaussian\n",
    "\n",
    "def linear_decay(init_val, final_val, cur_step, total_steps):\n",
    "    if cur_step >= total_steps:\n",
    "        return final_val\n",
    "    return (init_val * (total_steps - cur_step) +\n",
    "            final_val * cur_step) / total_steps\n",
    "\n",
    "def smoothen(values):\n",
    "    kernel = gaussian(100, std=100)\n",
    "    # kernel = np.concatenate([np.arange(100), np.arange(99, -1, -1)])\n",
    "    kernel = kernel / np.sum(kernel)\n",
    "    return convolve(values, kernel, 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7e5d6709",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                 | 2286/2999861 [01:05<23:49:45, 34.94it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_35740/3219533702.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     17\u001B[0m     \u001B[0;31m# train\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m     \u001B[0mobs_batch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mact_batch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreward_batch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnext_obs_batch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_done_batch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mexp_replay\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msample\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 19\u001B[0;31m     loss = compute_td_loss(obs_batch, act_batch, reward_batch, next_obs_batch, is_done_batch,\n\u001B[0m\u001B[1;32m     20\u001B[0m                     \u001B[0magent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtarget_network\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m                     \u001B[0mgamma\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.99\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_35740/1588500503.py\u001B[0m in \u001B[0;36mcompute_td_loss\u001B[0;34m(states, actions, rewards, next_states, is_done, agent, target_network, gamma, check_shapes, device)\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m     \u001B[0;31m# get q-values for all actions in current states\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 22\u001B[0;31m     \u001B[0mpredicted_qvalues\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0magent\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstates\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     23\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m     \u001B[0;31m# compute q-values for all actions in next states\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1051\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1052\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_35740/1944197674.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, state_t)\u001B[0m\n\u001B[1;32m     34\u001B[0m         \u001B[0mstate_t\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mReLU\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconv1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstate_t\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     35\u001B[0m         \u001B[0mstate_t\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mReLU\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconv2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstate_t\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 36\u001B[0;31m         \u001B[0mstate_t\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mReLU\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconv3\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstate_t\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     37\u001B[0m         \u001B[0mqvalues\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mReLU\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mFlatten\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstate_t\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1051\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1052\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    441\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    442\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 443\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_conv_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    444\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    445\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0mConv3d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_ConvNd\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001B[0m in \u001B[0;36m_conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    437\u001B[0m                             \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstride\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    438\u001B[0m                             _pair(0), self.dilation, self.groups)\n\u001B[0;32m--> 439\u001B[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001B[0m\u001B[1;32m    440\u001B[0m                         self.padding, self.dilation, self.groups)\n\u001B[1;32m    441\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "for step in trange(step, total_steps + 1):\n",
    "    if not is_enough_ram():\n",
    "        print('less that 100 Mb RAM available, freezing')\n",
    "        print('make sure everythin is ok and make KeyboardInterrupt to continue')\n",
    "        try:\n",
    "            while True:\n",
    "                pass\n",
    "        except KeyboardInterrupt:\n",
    "            pass\n",
    "\n",
    "    agent.epsilon = linear_decay(init_epsilon, final_epsilon, step, decay_steps)\n",
    "    #print(\"epsilon = {}\".format(agent.epsilon))\n",
    "    # play\n",
    "    _, state = play_and_record(state, agent, env, exp_replay, timesteps_per_epoch)\n",
    "    #print(\"Played!\")\n",
    "    # train\n",
    "    obs_batch, act_batch, reward_batch, next_obs_batch, is_done_batch = exp_replay.sample(batch_size)\n",
    "    loss = compute_td_loss(obs_batch, act_batch, reward_batch, next_obs_batch, is_done_batch,\n",
    "                    agent, target_network,\n",
    "                    gamma=0.99,\n",
    "                    check_shapes=False,\n",
    "                    device=device)\n",
    "    #print(\"Calculated Loss\")\n",
    "    #<YOUR CODE: sample batch_size of data from experience replay>\n",
    "\n",
    "    #loss = <YOUR CODE: compute TD loss>\n",
    "\n",
    "    loss.backward()\n",
    "    grad_norm = nn.utils.clip_grad_norm_(agent.parameters(), max_grad_norm)\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    #print(\"Backprop done!\")\n",
    "    if step % loss_freq == 0:\n",
    "        td_loss_history.append(loss.data.cpu().item())\n",
    "        grad_norm_history.append(grad_norm)\n",
    "\n",
    "    if step % refresh_target_network_freq == 0:\n",
    "        # Load agent weights into target_network\n",
    "        #target_network = DQNAgent(env).to(device)\n",
    "        target_network.load_state_dict(agent.state_dict())\n",
    "\n",
    "    if step % eval_freq == 0:\n",
    "        env = gym.make(ENV_NAME)\n",
    "        env.seed(seed)\n",
    "        env = PreprocessAtariObs(env)\n",
    "        env = FrameBuffer(env)\n",
    "        print(\"Started evaluating\")\n",
    "        print(\"start rw history\")\n",
    "        n_lives = 1\n",
    "        mean_rw_history.append(evaluate(\n",
    "            env, agent, n_games=3 * n_lives, greedy=True)\n",
    "        )\n",
    "        \n",
    "        env = gym.make(ENV_NAME)\n",
    "        env.seed(seed)\n",
    "        env = PreprocessAtariObs(env)\n",
    "        env = FrameBuffer(env)\n",
    "        print(\"Start init 'q' values\")\n",
    "        initial_state_q_values = agent.get_qvalues(\n",
    "            [env.reset()]\n",
    "        )\n",
    "        initial_state_v_history.append(np.max(initial_state_q_values))\n",
    "\n",
    "        clear_output(True)\n",
    "        print(\"buffer size = %i, epsilon = %.5f\" %\n",
    "              (len(exp_replay), agent.epsilon))\n",
    "\n",
    "        plt.figure(figsize=[16, 9])\n",
    "\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.title(\"Mean reward per life\")\n",
    "        plt.plot(mean_rw_history)\n",
    "        plt.grid()\n",
    "\n",
    "        assert not np.isnan(td_loss_history[-1])\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.title(\"TD loss history (smoothened)\")\n",
    "        plt.plot(smoothen(td_loss_history))\n",
    "        plt.grid()\n",
    "\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.title(\"Initial state V\")\n",
    "        plt.plot(initial_state_v_history)\n",
    "        plt.grid()\n",
    "\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.title(\"Grad norm history (smoothened)\")\n",
    "        plt.plot(smoothen(grad_norm_history))\n",
    "        plt.grid()\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a47f7fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}